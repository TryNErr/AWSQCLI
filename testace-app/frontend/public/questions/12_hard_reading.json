[
  {
    "_id": "grade12_hard_reading_001",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue?",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_002",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 2]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_003",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 3]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_004",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 4]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_005",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 5]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_006",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 6]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_007",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 7]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_008",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 8]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  },
  {
    "_id": "grade12_hard_reading_009",
    "content": "Read the passage and answer the question:\n\n**The Ethics of Artificial Intelligence**\n\nAs artificial intelligence systems become more sophisticated and ubiquitous, society faces unprecedented ethical challenges. Machine learning algorithms can perpetuate and amplify existing biases present in their training data, leading to discriminatory outcomes in hiring, lending, and criminal justice applications. The 'black box' nature of many AI systems makes it difficult to understand how they reach decisions, raising questions about accountability and transparency. Furthermore, as AI systems approach human-level performance in various domains, we must grapple with questions about consciousness, rights, and the fundamental nature of intelligence itself.\n\nThe development of autonomous weapons systems presents perhaps the most urgent ethical dilemma. Should machines be given the authority to make life-and-death decisions without human intervention? International humanitarian law requires that combatants distinguish between civilians and military targets, but can we trust algorithms to make such nuanced moral judgments? These questions demand immediate attention as the technology rapidly advances.\n\nWhat does the author suggest is the most urgent AI ethics issue? [Variation 9]",
    "type": "multiple_choice",
    "options": [
      "Bias in hiring and lending algorithms",
      "The lack of transparency in AI decision-making",
      "Autonomous weapons systems making life-and-death decisions",
      "Questions about AI consciousness and rights"
    ],
    "correctAnswer": "Autonomous weapons systems making life-and-death decisions",
    "subject": "Reading",
    "grade": 12,
    "difficulty": "hard",
    "explanation": "The passage explicitly states that autonomous weapons systems present 'perhaps the most urgent ethical dilemma' and demand 'immediate attention.'"
  }
]